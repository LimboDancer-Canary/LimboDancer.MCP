# ** 2 Vector index for Azure AI Search (hybrid)**

   * Files: `src/LimboDancer.MCP.Vector.AzureSearch/{SearchIndexBuilder.cs, VectorStore.cs}`, `tools/ai-search-index.json`.
   * Include fields for ontology filters (class, uri, tags) and embeddings (dim, profile).
   * Why: Milestone 3 requires vector+BM25 with ontology filters; the architecture expects a dedicated vector lib. &#x20;

---

here’s a **PR-ready vector layer** for Azure AI Search.

It includes:

* `src/LimboDancer.MCP.Vector.AzureSearch/SearchIndexBuilder.cs`
* `src/LimboDancer.MCP.Vector.AzureSearch/VectorStore.cs`
* `tools/ai-search-index.json`

The design supports **hybrid** (BM25 + vector) search and **ontology filters** (`ontologyClass`, `uri`, `tags`). Embedding generation is intentionally **decoupled** (you’ll pass vectors in, or inject a delegate that calls your Azure OpenAI embeddings).

### Note:
Additional Fields to support binding to `Tenant`:
**Index fields** (additions in bold):
`id`, `title`, `content`, `source`, `chunk`, `ontologyClass`, `uri`, `tags`, `vector`, **`tenant` (filterable, facetable), `package` (filterable), `channel` (filterable)**.

Define OData filterable attributes for the three new fields. All writes must set `tenant` (required); `package`/`channel` are optional but recommended.

---

## `src/LimboDancer.MCP.Vector.AzureSearch/SearchIndexBuilder.cs`

```csharp
// PRIMER:
// - Requires NuGet: Azure.Search.Documents (>= 11.6.*)
// - Creates or updates an index with fields for hybrid + ontology filters.
// - Vector field is configured with a profile name you choose (default: "vec-default").
// - You provide embedding dimensions (e.g., 1536 for text-embedding-3-small, 3072 for -3-large).

using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Azure;
using Azure.Search.Documents.Indexes;
using Azure.Search.Documents.Indexes.Models;

namespace LimboDancer.MCP.Vector.AzureSearch
{
    public sealed class SearchIndexBuilder
    {
        public const string DefaultIndexName = "ldm-memory";
        public const string DefaultVectorField = "embedding";
        public const string DefaultVectorProfile = "vec-default";
        public const string DefaultSemanticConfig = "semantic-config";

        public static async Task EnsureIndexAsync(
            SearchIndexClient indexClient,
            string indexName = DefaultIndexName,
            int embeddingDimensions = 3072,
            string vectorProfileName = DefaultVectorProfile,
            string semanticConfigName = DefaultSemanticConfig,
            CancellationToken ct = default)
        {
            ArgumentNullException.ThrowIfNull(indexClient);

            var fields = BuildFields(embeddingDimensions, vectorProfileName);
            var vectorSearch = BuildVectorSearch(vectorProfileName);
            var semantic = BuildSemantic(semanticConfigName);

            var index = new SearchIndex(indexName)
            {
                Fields = fields,
                VectorSearch = vectorSearch,
                SemanticSearch = semantic
            };

            // Create or update idempotently
            await indexClient.CreateOrUpdateIndexAsync(index, onlyIfUnchanged: false, ct);
        }

        private static IList<SearchField> BuildFields(int embeddingDimensions, string vectorProfileName)
        {
            // Key and common metadata
            var id = new SimpleField("id", SearchFieldDataType.String) { IsKey = true, IsFilterable = true, IsSortable = true };

            var title     = new SearchableField("title")   { IsFilterable = false, IsSortable = true,  IsFacetable = false, AnalyzerName = LexicalAnalyzerName.EnMicrosoft };
            var content   = new SearchableField("content") { IsFilterable = false, IsSortable = false, IsFacetable = false, AnalyzerName = LexicalAnalyzerName.EnMicrosoft };

            var source    = new SimpleField("source", SearchFieldDataType.String) { IsFilterable = true, IsSortable = true };
            var chunk     = new SimpleField("chunk", SearchFieldDataType.Int32)   { IsFilterable = true, IsSortable = true };
            var createdAt = new SimpleField("createdAt", SearchFieldDataType.DateTimeOffset) { IsFilterable = true, IsSortable = true };

            // Ontology filters
            var ontologyClass = new SimpleField("ontologyClass", SearchFieldDataType.String) { IsFilterable = true, IsSortable = true, IsFacetable = true };
            var uri           = new SimpleField("uri",           SearchFieldDataType.String) { IsFilterable = true, IsSortable = true };
            var tags          = new SearchField("tags", SearchFieldDataType.Collection(SearchFieldDataType.String))
            {
                IsFilterable = true,
                IsFacetable  = true,
                IsSortable   = false
            };

            // Arbitrary metadata (not searchable)
            var metadataJson = new SimpleField("metadataJson", SearchFieldDataType.String) { IsFilterable = false, IsSortable = false, IsFacetable = false, IsHidden = false };

            // Vector field
            var embedding = new SearchField(DefaultVectorField, SearchFieldDataType.Collection(SearchFieldDataType.Single))
            {
                IsSearchable = true,   // required for vector fields
                IsFilterable = false,
                IsSortable   = false,
                IsFacetable  = false,
                VectorSearchDimensions = embeddingDimensions,
                VectorSearchProfile = vectorProfileName
            };

            return new List<SearchField>
            {
                id, title, content, source, chunk, createdAt,
                ontologyClass, uri, tags, metadataJson, embedding
            };
        }

        private static VectorSearch BuildVectorSearch(string profileName)
        {
            // HNSW algorithm profile (app-provided vectors; no integrated vectorizer here)
            var algos = new List<VectorSearchAlgorithmConfiguration>
            {
                new HnswVectorSearchAlgorithmConfiguration("hnsw-1")
            };

            var profiles = new List<VectorSearchProfile>
            {
                new VectorSearchProfile(profileName, "hnsw-1")
            };

            return new VectorSearch(algorithms: algos, profiles: profiles);
        }

        private static SemanticSearch BuildSemantic(string semanticConfigName)
        {
            // Use content/title fields for semantic rerank (optional but good defaults)
            var cfg = new SemanticConfiguration(
                name: semanticConfigName,
                prioritizedFields: new SemanticPrioritizedFields()
                {
                    TitleField = new SemanticField("title"),
                    ContentFields = { new SemanticField("content") }
                });

            return new SemanticSearch(new[] { cfg });
        }
    }
}
```

---

## `src/LimboDancer.MCP.Vector.AzureSearch/VectorStore.cs`

```csharp
// PRIMER:
// - Abstraction for upserts and hybrid search.
// - You bring embeddings (float[]) or inject a delegate to produce them.
// - Ontology-aware filters: ontologyClass, uri, tags[] (OData filter).
//
// Requires NuGet: Azure.Search.Documents (>= 11.6.*)

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text.Json;
using System.Threading;
using System.Threading.Tasks;
using Azure;
using Azure.Search.Documents;
using Azure.Search.Documents.Models;

namespace LimboDancer.MCP.Vector.AzureSearch
{
    public sealed class VectorStore
    {
        private readonly SearchClient _client;

        // Optional embedding producer if you want this layer to embed text on the fly.
        private readonly Func<string, Task<float[]>>? _embed;

        public VectorStore(SearchClient client, Func<string, Task<float[]>>? embed = null)
        {
            _client = client ?? throw new ArgumentNullException(nameof(client));
            _embed = embed;
        }

        // ------------ Document model (match ai-search-index.json) ------------

        public sealed class MemoryDoc
        {
            public string Id { get; set; } = Guid.NewGuid().ToString("N");
            public string? Title { get; set; }
            public string Content { get; set; } = string.Empty;

            public string? Source { get; set; }
            public int? Chunk { get; set; }
            public DateTimeOffset? CreatedAt { get; set; }

            public string? OntologyClass { get; set; }
            public string? Uri { get; set; }
            public IList<string>? Tags { get; set; }

            public string? MetadataJson { get; set; }
            public IList<float>? Embedding { get; set; }
        }

        // ---------------------------- UPSERT ---------------------------------

        public async Task UpsertAsync(IEnumerable<MemoryDoc> docs, bool embedIfMissing = false, CancellationToken ct = default)
        {
            var list = docs.ToList();

            if (embedIfMissing && _embed is not null)
            {
                foreach (var d in list.Where(d => d.Embedding is null || d.Embedding.Count == 0))
                {
                    d.Embedding = (await _embed(d.Content)).ToList();
                }
            }

            var batch = IndexDocumentsBatch.MergeOrUpload(list.Select(l => (SearchDocument)ToSearchDocument(l)));
            var resp = await _client.IndexDocumentsAsync(batch, ct);

            // Optionally surface any per-item failures
            var failed = resp.Value.Results.Where(r => r.Succeeded == false).ToList();
            if (failed.Count > 0)
            {
                var errors = string.Join("; ", failed.Select(f => $"{f.Key}:{f.ErrorMessage}"));
                throw new InvalidOperationException($"Index upsert had failures: {errors}");
            }
        }

        private static SearchDocument ToSearchDocument(MemoryDoc d)
        {
            var sd = new SearchDocument
            {
                ["id"] = d.Id,
                ["title"] = d.Title ?? "",
                ["content"] = d.Content ?? "",
                ["source"] = d.Source ?? "",
                ["chunk"] = d.Chunk ?? 0,
                ["createdAt"] = d.CreatedAt ?? DateTimeOffset.UtcNow,
                ["ontologyClass"] = d.OntologyClass ?? "",
                ["uri"] = d.Uri ?? "",
                ["tags"] = d.Tags ?? Array.Empty<string>(),
                ["metadataJson"] = d.MetadataJson ?? ""
            };

            if (d.Embedding is not null && d.Embedding.Count > 0)
            {
                sd["embedding"] = d.Embedding;
            }

            return sd;
        }

        // -------------------------- HYBRID SEARCH ----------------------------

        public sealed class SearchFilters
        {
            public string? OntologyClass { get; set; }
            public string? UriEquals { get; set; }
            public IReadOnlyList<string>? TagsAny { get; set; }
            public DateTimeOffset? CreatedAfter { get; set; }
            public DateTimeOffset? CreatedBefore { get; set; }
        }

        public sealed class SearchResultItem
        {
            public string Id { get; init; } = "";
            public string? Title { get; init; }
            public string Content { get; init; } = "";
            public string? Source { get; init; }
            public int? Chunk { get; init; }
            public string? OntologyClass { get; init; }
            public string? Uri { get; init; }
            public IReadOnlyList<string>? Tags { get; init; }
            public double? Score { get; init; }
            public string? MetadataJson { get; init; }
        }

        /// <summary>
        /// Hybrid search: BM25 query + vector KNN (optional). Provide either or both.
        /// If vector is null and _embed is available, we embed the query text.
        /// </summary>
        public async Task<IReadOnlyList<SearchResultItem>> SearchHybridAsync(
            string? queryText,
            float[]? vector,
            int k = 8,
            SearchFilters? filters = null,
            CancellationToken ct = default)
        {
            if (vector is null && string.IsNullOrWhiteSpace(queryText))
                throw new ArgumentException("Provide query text and/or vector.");

            // If no vector but we can embed, embed the text
            if (vector is null && _embed is not null && !string.IsNullOrWhiteSpace(queryText))
            {
                vector = await _embed(queryText!);
            }

            var options = new SearchOptions
            {
                IncludeTotalCount = false,
                Size = k,
                QueryType = SearchQueryType.Simple,
                SemanticSearch = new SemanticSearchOptions()
                {
                    // Use the semantic config we created in the index builder (if present)
                    // If your service has semantic off, this is ignored.
                    ConfigurationName = SearchIndexBuilder.DefaultSemanticConfig
                }
            };

            if (!string.IsNullOrWhiteSpace(queryText))
            {
                options.SearchFields.Add("title");
                options.SearchFields.Add("content");
            }

            var filter = BuildFilter(filters);
            if (!string.IsNullOrWhiteSpace(filter))
                options.Filter = filter;

            if (vector is not null)
            {
                options.VectorSearch = new()
                {
                    Queries =
                    {
                        new VectorizedQuery(vector)
                        {
                            KNearestNeighborsCount = k,
                            Fields = { "embedding" }
                        }
                    }
                };
            }

            // Execute
            var resp = await _client.SearchAsync<SearchDocument>(queryText ?? "*", options, ct);

            var items = new List<SearchResultItem>();
            await foreach (var r in resp.Value.GetResultsAsync())
            {
                var d = r.Document;
                items.Add(new SearchResultItem
                {
                    Id = d.GetString("id"),
                    Title = d.TryGetValue("title", out object? t) ? t as string : null,
                    Content = d.GetString("content"),
                    Source = d.TryGetValue("source", out object? s) ? s as string : null,
                    Chunk = d.TryGetValue("chunk", out object? c) ? (int?)Convert.ToInt32(c) : null,
                    OntologyClass = d.TryGetValue("ontologyClass", out object? oc) ? oc as string : null,
                    Uri = d.TryGetValue("uri", out object? u) ? u as string : null,
                    Tags = d.TryGetValue("tags", out object? tg) ? (tg as IEnumerable<object>)?.Select(x => x?.ToString() ?? "").ToList() : null,
                    MetadataJson = d.TryGetValue("metadataJson", out object? mj) ? mj as string : null,
                    Score = r.Score
                });
            }
            return items;
        }

        private static string? BuildFilter(SearchFilters? f)
        {
            if (f is null) return null;
            var parts = new List<string>();

            if (!string.IsNullOrWhiteSpace(f.OntologyClass))
                parts.Add($"ontologyClass eq '{EscapeOData(f.OntologyClass)}'");

            if (!string.IsNullOrWhiteSpace(f.UriEquals))
                parts.Add($"uri eq '{EscapeOData(f.UriEquals)}'");

            if (f.TagsAny is { Count: > 0 })
            {
                // tags/any(t: t eq 'A' or t eq 'B')
                var tagOrs = string.Join(" or ", f.TagsAny.Select(t => $"t eq '{EscapeOData(t)}'"));
                parts.Add($"tags/any(t: {tagOrs})");
            }

            if (f.CreatedAfter is { } a)
                parts.Add($"createdAt ge {a:O}");

            if (f.CreatedBefore is { } b)
                parts.Add($"createdAt le {b:O}");

            return parts.Count > 0 ? string.Join(" and ", parts) : null;
        }

        private static string EscapeOData(string s) => s.Replace("'", "''");
    }

    internal static class SearchDocumentExtensions
    {
        public static string GetString(this SearchDocument d, string field)
            => d.TryGetValue(field, out object? v) ? v?.ToString() ?? "" : "";

        public static bool TryGetValue(this SearchDocument d, string field, out object? value)
            => d.TryGetValue(field, out value);
    }
}
```

---

## `tools/ai-search-index.json`

```json
{
  "name": "ldm-memory",
  "fields": [
    { "name": "id",            "type": "Edm.String",           "key": true,  "filterable": true,  "sortable": true,  "facetable": false },
    { "name": "title",         "type": "Edm.String",           "searchable": true, "analyzer": "en.microsoft", "filterable": false, "sortable": true,  "facetable": false },
    { "name": "content",       "type": "Edm.String",           "searchable": true, "analyzer": "en.microsoft", "filterable": false, "sortable": false, "facetable": false },

    { "name": "source",        "type": "Edm.String",           "searchable": false, "filterable": true, "sortable": true,  "facetable": false },
    { "name": "chunk",         "type": "Edm.Int32",            "searchable": false, "filterable": true, "sortable": true,  "facetable": false },
    { "name": "createdAt",     "type": "Edm.DateTimeOffset",   "searchable": false, "filterable": true, "sortable": true,  "facetable": false },

    { "name": "ontologyClass", "type": "Edm.String",           "searchable": false, "filterable": true, "sortable": true,  "facetable": true  },
    { "name": "uri",           "type": "Edm.String",           "searchable": false, "filterable": true, "sortable": true,  "facetable": false },
    { "name": "tags",          "type": "Collection(Edm.String)","searchable": false, "filterable": true, "sortable": false, "facetable": true  },

    { "name": "metadataJson",  "type": "Edm.String",           "searchable": false, "filterable": false, "sortable": false, "facetable": false },

    {
      "name": "embedding",
      "type": "Collection(Edm.Single)",
      "searchable": true,
      "filterable": false,
      "sortable": false,
      "facetable": false,
      "dimensions": 3072,
      "vectorSearchProfile": "vec-default"
    }
  ],
  "vectorSearch": {
    "algorithms": [
      { "name": "hnsw-1", "kind": "hnsw" }
    ],
    "profiles": [
      { "name": "vec-default", "algorithmConfiguration": "hnsw-1" }
    ]
  },
  "semantic": {
    "configurations": [
      {
        "name": "semantic-config",
        "prioritizedFields": {
          "titleField":   { "fieldName": "title" },
          "contentFields":[ { "fieldName": "content" } ]
        }
      }
    ]
  }
}
```

> Notes
>
> * **dimensions**: set to your embedding model (e.g., 1536 for `text-embedding-3-small`, 3072 for `-3-large`).
> * This index expects **you** to provide vectors (no integrated vectorizer configured).
> * Keep the **profile** name (`vec-default`) aligned with the vector field and your code.
> * Semantic is optional; if your service/sku does not support it, Azure will ignore that section.

---

### Quick wiring (example)

```csharp
// In your Composition Root (e.g., McpServer.Http Program.cs)
using Azure;
using Azure.Search.Documents;
using Azure.Search.Documents.Indexes;
using LimboDancer.MCP.Vector.AzureSearch;

// Build clients (endpoint & key from config or Managed Identity)
var endpoint = new Uri(builder.Configuration["Search:Endpoint"]);
var key = new AzureKeyCredential(builder.Configuration["Search:ApiKey"]);
var indexName = "ldm-memory";

var indexClient = new SearchIndexClient(endpoint, key);
await SearchIndexBuilder.EnsureIndexAsync(indexClient, indexName, embeddingDimensions: 3072);

var searchClient = new SearchClient(endpoint, indexName, key);

// Optional: inject an embedding delegate if you want on-the-fly embeddings here
Func<string, Task<float[]>>? embed = null; // or wire your Azure OpenAI embeddings provider
builder.Services.AddSingleton(new VectorStore(searchClient, embed));
```

I can also add a **tiny ingest sample** that chunks a document, calls your embeddings, upserts into the index, and then demonstrates a **hybrid search** with `ontologyClass` and `tags` filters, below.

---

### Tiny ingest & hybrid search sample

**File:** `samples/VectorIngestSample/Program.cs`

> Demonstrates: simple chunking → Azure OpenAI embeddings → upsert to Azure AI Search → hybrid search (BM25 + vector) with ontology filters.

```csharp
// dotnet add package Azure.Search.Documents
// dotnet add package Azure.AI.OpenAI
// Project refs: LimboDancer.MCP.Vector.AzureSearch

using System.Text;
using Azure;
using Azure.AI.OpenAI;
using Azure.Search.Documents;
using Azure.Search.Documents.Indexes;
using LimboDancer.MCP.Vector.AzureSearch;
using static LimboDancer.MCP.Vector.AzureSearch.VectorStore;

var searchEndpoint  = GetEnv("AZURE_SEARCH_ENDPOINT");     // e.g. https://<service>.search.windows.net
var searchApiKey    = GetEnv("AZURE_SEARCH_API_KEY");
var indexName       = EnvOr("AZURE_SEARCH_INDEX", SearchIndexBuilder.DefaultIndexName);

var aoaiEndpoint    = GetEnv("AZURE_OPENAI_ENDPOINT");     // e.g. https://<resource>.openai.azure.com
var aoaiApiKey      = GetEnv("AZURE_OPENAI_API_KEY");
var embeddingModel  = EnvOr("AZURE_OPENAI_EMBEDDING_MODEL", "text-embedding-3-large"); // dims=3072 (adjust index dims if you change)

var samplePath      = Environment.GetEnvironmentVariable("SAMPLE_PATH"); // optional file to ingest
var title           = EnvOr("SAMPLE_TITLE", "Sample Travel Policy");
var source          = EnvOr("SAMPLE_SOURCE", "docs/travel-policy.md");
var ontologyClass   = EnvOr("SAMPLE_ONTOLOGY_CLASS", "ldm:MemoryItem");
var tagsCsv         = EnvOr("SAMPLE_TAGS", "kind:vector,domain:travel");

var searchIndexClient = new SearchIndexClient(new Uri(searchEndpoint), new AzureKeyCredential(searchApiKey));
await SearchIndexBuilder.EnsureIndexAsync(searchIndexClient, indexName, embeddingDimensions: 3072);

var searchClient = new SearchClient(new Uri(searchEndpoint), indexName, new AzureKeyCredential(searchApiKey));
var openAI       = new OpenAIClient(new Uri(aoaiEndpoint), new AzureKeyCredential(aoaiApiKey));

// Embedding delegate used by VectorStore (also used for document embeddings below)
async Task<float[]> EmbedAsync(string text)
{
    var resp = await openAI.GetEmbeddingsAsync(
        new EmbeddingsOptions(embeddingModel, new[] { text }));
    // Azure SDK returns ReadOnlyMemory<float>; convert to float[]
    return resp.Value.Data[0].Embedding.ToArray();
}

var store = new VectorStore(searchClient, EmbedAsync);

// ---------------- Ingest ----------------
var text = !string.IsNullOrWhiteSpace(samplePath) && File.Exists(samplePath)
    ? await File.ReadAllTextAsync(samplePath)
    : DefaultSampleText();

var chunks = Chunk(text, maxChars: 1200);
Console.WriteLine($"Chunks: {chunks.Count}");

var now = DateTimeOffset.UtcNow;
var docs = new List<MemoryDoc>();
for (int i = 0; i < chunks.Count; i++)
{
    var id = $"{Guid.NewGuid():N}";
    docs.Add(new MemoryDoc
    {
        Id = id,
        Title = title,
        Content = chunks[i],
        Source = source,
        Chunk = i,
        CreatedAt = now,
        OntologyClass = ontologyClass,
        Uri = $"ldm:MemoryItem#{id}",
        Tags = tagsCsv.Split(',', StringSplitOptions.RemoveEmptyEntries | StringSplitOptions.TrimEntries),
        // Compute embeddings now (so upsert is single-batch)
        Embedding = await EmbedAsync(chunks[i])
    });
}

await store.UpsertAsync(docs, embedIfMissing: false);
Console.WriteLine("Upsert complete.");

// ---------------- Hybrid search ----------------
var query = EnvOr("SAMPLE_QUERY", "What are the cancellation and baggage rules?");
var filters = new SearchFilters
{
    OntologyClass = ontologyClass,
    TagsAny = new[] { "domain:travel" }
};

var results = await store.SearchHybridAsync(queryText: query, vector: null, k: 5, filters: filters);
Console.WriteLine($"\nQuery: {query}\nTop {results.Count} results:");
foreach (var r in results)
{
    var preview = r.Content.Length > 160 ? r.Content[..160] + "..." : r.Content;
    Console.WriteLine($"- [{r.Score:F3}] {r.Title}  ({r.Source}#{r.Chunk})\n  {preview}\n");
}

// ---------------- Helpers ----------------
static string GetEnv(string name)
{
    var v = Environment.GetEnvironmentVariable(name);
    if (string.IsNullOrWhiteSpace(v))
        throw new InvalidOperationException($"Missing required environment variable: {name}");
    return v;
}
static string EnvOr(string name, string fallback) => Environment.GetEnvironmentVariable(name) ?? fallback;

/// Simple, token-agnostic chunker by paragraphs/sentences and a max char budget.
static List<string> Chunk(string text, int maxChars = 1200)
{
    var parts = SplitSentences(text);
    var chunks = new List<string>();
    var sb = new StringBuilder(maxChars + 128);

    foreach (var s in parts)
    {
        if (sb.Length + s.Length + 1 > maxChars && sb.Length > 0)
        {
            chunks.Add(sb.ToString().Trim());
            sb.Clear();
        }
        sb.AppendLine(s);
    }
    if (sb.Length > 0) chunks.Add(sb.ToString().Trim());
    return chunks;
}

static IEnumerable<string> SplitSentences(string text)
{
    // naive splitter: split on blank lines, then on '. ' boundaries
    foreach (var para in text.Split(new[] { "\r\n\r\n", "\n\n" }, StringSplitOptions.RemoveEmptyEntries))
    {
        var p = para.Replace("\r\n", " ").Replace('\n', ' ').Trim();
        if (p.Length == 0) continue;

        var acc = new StringBuilder();
        foreach (var token in p.Split(' '))
        {
            acc.Append(token);
            acc.Append(' ');
            if (token.EndsWith('.') || token.EndsWith('!') || token.EndsWith('?'))
            {
                yield return acc.ToString().Trim();
                acc.Clear();
            }
        }
        if (acc.Length > 0) yield return acc.ToString().Trim();
    }
}

static string DefaultSampleText() => """
Contoso Travel: Flight and Baggage Policy

Tickets are refundable within 24 hours of purchase when booked at least 7 days before departure. After 24 hours, standard change fees apply unless a Flex fare was purchased.

Carry-on baggage must fit in the overhead bin or under the seat and should not exceed airline limits. Checked baggage fees vary by route; oversized or overweight items incur additional charges.

Cancellations due to severe weather or airline irregular operations may qualify for penalty waivers. Contact support with your reservation number to review options.
""";
```

**Run:**

```bash
# Required
export AZURE_SEARCH_ENDPOINT="https://<service>.search.windows.net"
export AZURE_SEARCH_API_KEY="<key>"
export AZURE_OPENAI_ENDPOINT="https://<resource>.openai.azure.com"
export AZURE_OPENAI_API_KEY="<key>"

# Optional
export AZURE_SEARCH_INDEX="ldm-memory"
export AZURE_OPENAI_EMBEDDING_MODEL="text-embedding-3-large"
export SAMPLE_PATH="./docs/travel-policy.md"
export SAMPLE_TITLE="Contoso Travel Policy"
export SAMPLE_SOURCE="docs/travel-policy.md"
export SAMPLE_ONTOLOGY_CLASS="ldm:MemoryItem"
export SAMPLE_TAGS="kind:vector,domain:travel"
export SAMPLE_QUERY="What is the baggage policy?"

dotnet run --project samples/VectorIngestSample
```

> Notes
> • If you switch to `text-embedding-3-small` (1536 dims), also change the index dimensions (in `EnsureIndexAsync(...)` and `tools/ai-search-index.json`).
> • The sample embeds chunks **before** upsert for a single batch write. You can set `embedIfMissing:true` and omit `Embedding` fields if you prefer on-the-fly embeddings in `VectorStore`.
> • For production, replace the naive chunker with a token-aware one and add content hashing to make upserts idempotent.

